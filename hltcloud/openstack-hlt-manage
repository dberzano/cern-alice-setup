#!/bin/bash

# openstack-hlt-manage -- by Dario Berzano <dario.berzano@cern.ch>
#
# Control which HLT nodes are part of the OpenStack cluster.

# Color definitions
export Cc="\033[36m"
export Cm="\033[35m"
export Cy="\033[33m"
export Cb="\033[34m"
export Cr="\033[31m"
export Cg="\033[32m"
export Cz="\033[m"

# Set to 0 to enable commands
export dry=1

# Set to 1 to have each echo output a line return at the end (useful with pdsh)
export line_output=0

# Set to 1 to enable parallel execution (via pdsh)
export parallel_exec=0

# SSH key. In the production configuration, this is substituted by Puppet. In
# any other case, it can be specified from the command line
export sshConfigFile='<%= @os_enable_disable_config %>'

# Wrap a command, prints it on screen before executing it. Execute it for real
# only if dry=0. Preserve its exit state.
#
# Usage: wrap <msg> <cmd> [param1 [param2 [param3...]]]
function wrap() {
  local r
  local err=$(mktemp)
  local out=$(mktemp)
  local msg="$1"
  shift

  if [[ $line_output == 0 ]] ; then
    echo -e -n "[....] ${Cc}${msg}${Cz}"
  else
    echo -e "${Cc}${msg}: operation started${Cz}"
  fi

  # Dry run?
  if [[ $dry == 0 ]] ; then
    "$@" > "$out" 2> "$err"
    r=$?
  else
    r=0
  fi

  if [[ $dry == 1 ]] ; then
    if [[ $line_output == 0 ]] ; then
      echo -e "\r[${Cy}FAKE${Cz}]"
    else
      echo -e "${Cy}${msg}: dry run${Cz}"
    fi
  elif [[ $r == 0 ]] ; then
    if [[ $line_output == 0 ]] ; then
      echo -e "\r[ ${Cg}OK${Cz} ]"
    else
      echo -e "${Cg}${msg}: OK${Cz}"
    fi
  else
    if [[ $line_output == 0 ]] ; then
      echo -e "\r[${Cr}FAIL${Cz}]"
    else
      echo -e "${Cr}${msg}: failed, errors follow${Cz}"
    fi

    echo -e "\n${Cy}=== COMMAND FAILED === ${Cz}"
    echo -e "${Cm}Command: ${Cr}${@}${Cz}"
    echo -e "${Cm}Exit code: ${Cr}${r}${Cz}"

    if [[ -s $out ]] ; then
      echo -e "\n${Cy}=== STDOUT === ${Cz}"
      cat "$out"
    fi

    if [[ -s $err ]] ; then
      echo -e "\n${Cy}=== STDERR === ${Cz}"
      cat "$err"
    fi

    echo ''
  fi

  rm -f "$err" "$out"

  return $r
}

# Executes the given command for each of the hypervisors given as last
# parameters.
#
# Executes all commands, even if they fail, and return 0 only if no command
# failed.
#
# Usage: forEach <command> [hyp1 [hyp2 [hyp3...]]]
function forEach() (
  local cmd="$1"
  local err_count=0
  local hyp
  shift

  for hyp in "$@" ; do
    "$cmd" "$hyp"
    [[ $? == 0 ]] || err_count=$((err_count+1))
  done

  if [[ $err_count == 0 ]] ; then
    [[ $line_output == 0 ]] && echo
    echo -e "${Cg}All commands executed successfully.${Cz}"
    return 0
  else
    [[ $line_output == 0 ]] && echo
    echo -e "${Cr}There were errors.${Cz}"
    return 1
  fi

)

# Just delete all virtual machines running on a certain hypervisor.
#
# Usage: deleteAllVmsOnHypervisor <full_host_name>
function deleteAllVmsOnHypervisor() (

  local host="$1"
  local nova_tmp
  local nova_filtered_tmp
  local err_count=0

  # Get IDs of the instances running on $host
  nova_tmp=$(mktemp)
  nova_filtered_tmp=$(mktemp)
  nova hypervisor-servers "$host" 2> /dev/null > "$nova_tmp"
  if [[ $? == 0 ]] ; then

    cat "$nova_tmp" 2> /dev/null | \
      grep -E '\|\s*instance-' | \
      sed -e 's/|//g' | \
      awk '{ print $1 }' > "$nova_filtered_tmp"

    exec 3< "$nova_filtered_tmp"

    # Delete instances
    while read -u 3 iid ; do
      wrap "Deleting VM ${iid} on hypervisor ${host}" nova delete "$iid"
      [[ $? == 0 ]] || err_count=$((err_count+1))
    done

    exec 3<&-

  else
    echo -e "${Cr}Cannot read the list of VMs!${Cz}"
    err_count=1
  fi

  rm -f "$nova_tmp" "$nova_filtered_tmp"

  [[ $err_count == 0 ]] && return 0
  return 1
)

# Wait for all virtual machines running on a hypervisor to disappear. There is
# also a timeout.
#
# Usage: waitVmsOnHypervisor <full_host_name> <timeout_seconds>
function waitVmsOnHypervisor() (

  local host="$1"
  local timeout_s="$2"
  local time_left_s
  local old_nvms='-1'
  local nvms='-1'
  local nova_tmp=$(mktemp)
  local i
  local r

  if [[ $line_output == 0 ]] ; then
    echo -e -n "${Cb}Waiting max ${timeout_s} s for VMs to be deleted on ${Cm}${host}${Cb}...${Cz}"
  else
    echo -e "${Cc}Waiting max ${timeout_s} s for VMs to be deleted on ${host}${Cz}"
  fi

  for (( i=0 ; i<$timeout_s ; i++ )) ; do

    if [[ $dry == 0 ]] ; then
      nova hypervisor-servers "$host" 2> /dev/null > "$nova_tmp"
      r=$?
    else
      r=0
    fi

    if [[ $r == 0 || $dry == 1 ]] ; then
      old_nvms=$nvms
      if [[ $dry == 1 ]] ; then
        # No VMs running in dry mode
        nvms=0
      else
        nvms=$( cat "$nova_tmp" | grep '^|' | grep -v '^|\s*ID' | wc -l )
      fi
      if [[ $nvms == 0 ]] ; then
        if [[ $line_output == 0 ]] ; then
          echo -e "${Cg}all gone in ${i}s!${Cz}"
        else
          echo -e "${Cg}All VMs gone in ${i} s${Cz}"
        fi
        rm -f "$nova_tmp"
        return 0
      elif [[ $nvms != $old_nvms || $(( $i % 10 )) == 0 ]] ; then
        time_left_s=$(( $timeout_s - $i ))
        if [[ $line_output == 0 ]] ; then
          echo -e -n "${Cy}${nvms} running (${time_left_s} s left)...${Cz}"
        else
          echo -e "${Cy}VMs running on ${host}: ${nvms} - timeout in ${time_left_s} s${Cz}"
        fi
      else
        [[ $line_output == 0 ]] && echo -e -n "${Cb}.${Cz}"
      fi
    else
      # nova hypervisor-servers returned nonzero
      if [[ $line_output == 0 ]] ; then
        echo -e -n "${Cr}X${Cz}"
      else
        echo -e "${Cr}Querying for VMs on ${host} returned an error: we keep retrying${Cz}"
      fi
    fi
    sleep 1
  done

  rm -f "$nova_tmp"
  if [[ $line_output == 0 ]] ; then
    echo -e "${Cr}timeout reached, giving up${Cz}"
  else
    echo -e "${Cr}VMs still running ${timeout_s}s: timeout reached, giving up${Cz}"
  fi
  return 1
)

# Deletes all virtual machines running on the specified hypervisor and disables
# it: no new virtual machine will land there. OpenStack daemons and their
# dependencies are started.
#
# Usage: disableHypervisor <full_host_name>
function disableHypervisor() (

  local host="$1"
  local err_count=0

  # Disable the OpenStack service: prevents scheduling of VMs there
  wrap "Disabling hypervisor ${host}" \
    nova-manage service disable --host="$host" --service=nova-compute
  if [[ $? != 0 ]] ; then
    echo -e "${Cr}Cannot procede with deletion of VMs on ${host}!${Cz}"
    return 1
  fi

  # Daemons must be enabled in order to delete stale VMs
  startDaemons "$host"

  if [[ $? == 0 ]] ; then

    # Delete all VMs running on the host
    deleteAllVmsOnHypervisor "$host"
    if [[ $? != 0 ]] ; then
      err_count=1
    else
      # Wait for VMs to disappear (timeout: 300 s)
      waitVmsOnHypervisor "$host" 300
    fi

  fi

  # Shut down all OpenStack-related daemons running on the host (must be
  # supported by an SSH key on the remote side for security reasons)
  wrap "Shutting down OpenStack daemons on ${host}" \
    sh -c "echo disable | ssh -F \"$sshConfigFile\" $host"
  [[ $? == 0 ]] || err_count=$((err_count+1))

  [[ $err_count == 0 ]] && return 0
  return 1
)

# Just starts daemons on the specified hypervisor.
#
# Usage: startDaemons <full_host_name>
function startDaemons() (
  local host="$1"

  # Turn on all OpenStack-related daemons running on the host
  wrap "Starting OpenStack daemons on ${host}" \
    sh -c "echo enable | ssh -F \"$sshConfigFile\" $host" || return $?
)

# Reenables an hypervisor: it will be available again to accept new virtual
# machines. OpenStack daemons and dependencies are started.
#
# Usage: enableHypervisor <full_host_name>
function enableHypervisor() (
  local host="$1"
  startDaemons "$host"
  wrap "Enabling hypervisor ${host}" \
    nova-manage service enable --host="$host" --service=nova-compute
  return $?
)

# Prints the status of all hypervisors. Parameter tells whether to turn on or
# off the query which displays the number of virtual machines.
#
# Usage: statusHypervisors [0|1]
function statusHypervisors() (
  local host
  local status status_str
  local alive alive_str
  local qnvms="$1"
  local hdr_txt='| Hypervisor           | Runs VMs? | Alive? |'
  local hdr_sep='+----------------------+-----------+--------+'
  local nova_tmp=$(mktemp)

  if [[ $qnvms == 1 ]] ; then
    hdr_txt="${hdr_txt} #VMs |"
    hdr_sep="${hdr_sep}------+"
  fi

  echo -e "${hdr_sep}\n${hdr_txt}\n${hdr_sep}"

  nova-manage service list 2> /dev/null | grep ^nova-compute | sort > "$nova_tmp"

  exec 3< "$nova_tmp"
  while read -u 3 rawline ; do
    host=$( echo "$rawline" | awk '{print $2}' )    # hypervisor's name
    status=$( echo "$rawline" | awk '{print $4}' )  # enabled/disabled
    alive=$( echo "$rawline" | awk '{print $5}' )   # :-) / XXX

    if [[ $qnvms == 1 ]] ; then
      # nova hypervisor-show gives an unreliable running_vms field: we use
      # another command here
      nvms=$( nova hypervisor-servers "$host" | \
        grep '^|' | grep -v '^|\s*ID' | wc -l 2> /dev/null )
    fi

    if [[ $status == enabled ]] ; then
      status=1
      status_str="${Cg}yes${Cz}"
    elif [[ $status == disabled ]] ; then
      status=0
      status_str="${Cr}no ${Cz}"
    else
      rm -f "$nova_tmp"
      die 'Status is neither enabled nor disabled'
    fi

    if [[ $alive == ':-)' ]] ; then
      alive=1
      alive_str="${Cg}alive${Cz}"
    elif [[ $alive == 'XXX' ]] ; then
      alive=0
      alive_str="${Cr}dead ${Cz}"
    else
      die 'Host state is neither :-) nor XXX'
    fi

    printf "| %-20s | " "$host"
    echo -e -n "   ${status_str}    | "
    echo -e -n "${alive_str}  |"
    [[ $qnvms == 1 ]] && printf " %4d | " $nvms
    echo ''

  done
  exec 3<&-

  rm -f "$nova_tmp"
  echo "${hdr_sep}"
  echo ''
  echo -e "${Cy}Note:${Cz} ${Cg}alive${Cz}/${Cr}dead${Cz} status is updated asynchronously."
  echo -e "      If you have just disabled a node it may still show as ${Cg}alive${Cz} for ~2 mins."
)

# Entry point
function main() (

  local action
  local r
  local nvms=0
  local prog=$(basename "$0")
  local full_prog
  local print_help=0
  local print_dry_notice=0
  local parallel_opts=()
  local all_args=("$@")

  full_prog=$(dirname "$0")
  full_prog=$(cd "$full_prog";pwd)
  full_prog="${full_prog}/${prog}"

  # Options to pass to each worker when running in parallel. Each option should
  # be appended to this array if you want it to be passed to the worker
  parallel_opts+=('--line-output')

  while [[ $# -gt 0 ]] ; do
    case "$1" in
      --for-real)
        dry=0
        parallel_opts+=("$1")
        shift
      ;;
      --line-output)
        line_output=1
        shift
      ;;
      --no-colors)
        for v in Cc Cm Cy Cb Cr Cg Cz ; do
          eval "export $v=''"
        done
        shift
      ;;
      --parallel)
        parallel_exec=1
        shift
      ;;
      --ssh-config)
        sshConfigFile="$2"
        shift ; shift
      ;;
      --nvms)
        nvms=1
        shift
      ;;
      *)
        break;
      ;;
    esac
  done

  action="$1"
  shift

  if [[ ${sshConfigFile:0:1} == '<' || ${sshConfigFile} == '' ]] ; then
    # Default SSH config file if none is specified
    export sshConfigFile="$HOME/.ssh/config"
  fi

  case "$action" in
    enable|disable)
      if [[ "$@" != '' ]] ; then
        if [[ $parallel_exec == 1 ]] ; then
          # Parallel execution with "pdsh -R exec"
          hosts_list=$( echo "$@" | sed -e 's/ /,/g' )
          pdsh -R exec -w "$hosts_list" \
            "$full_prog" "${parallel_opts[@]}" "$action" '%h'
          r=$?
        else
          # Single core
          forEach "${action}Hypervisor" "$@"
          r=$?
        fi
        print_dry_notice=1
      else
        print_help=1
      fi
    ;;
    status)
      statusHypervisors "$nvms"
      r=$?
    ;;
    *)
      [[ $action != '' ]] && echo -e "${Cr}Unknown action: ${Cc}${action}${Cz}"
      print_help=1
      r=1
    ;;
  esac

  if [[ $print_help == 1 ]] ; then
    echo -e "\n${Cm}Usage: ${Cc}${prog}${Cz}" \
      "[${Cc}--for-real${Cz}] [${Cc}--no-colors${Cz}] [${Cc}--line-output${Cz}] [${Cc}--parallel${Cz}] [${Cc}--ssh-config${Cz} ${Cy}<file>${Cz}] [${Cc}--nvms${Cz}]" \
      "[${Cg}enable${Cz}|${Cr}disable${Cz}|${Cy}status${Cz}]" \
      "[${Cc}node1${Cz} [${Cc}node2${Cz}...]]${Cz}\n"

    echo -e "         ${Cc}--for-real${Cz}     without this flag, ${Cg}enable${Cz} and" \
      "${Cr}disable${Cz} are just simulated and not executed"
    echo -e "         ${Cc}--no-colors${Cz}    turn off colors"
    echo -e "         ${Cc}--line-output${Cz}  line-buffered output (useful with pdsh)"
    echo -e "         ${Cc}--parallel${Cz}     use pdsh for executing in parallel with pdsh"
    echo -e "         ${Cc}--ssh-config${Cz}   SSH config file for running remote commands"
    echo -e "         ${Cc}--nvms${Cz}         report num of VMs running on each host when" \
      "executing ${Cy}status${Cz} (slow)"

    echo
  fi

  if [[ $dry == 1 && $print_dry_notice == 1 ]] ; then
    if [[ $line_output == 1 ]] ; then
      echo -e "${Cy}Note:${Cc} this was a dry run.${Cz}"
    else
      echo
      echo -e "${Cy}Note:${Cc} the command was not executed for real: it was a dry run.${Cz}"
      echo -e "${Cy}Add the ${Cc}--for-real${Cy} switch to execute it, i.e.:${Cz}"
      echo
      echo -e "  ${Cm}${prog} --for-real ${all_args[@]}${Cz}"
      echo
    fi
  fi

  return $?
)

# Entry point
main "$@" || return $?
